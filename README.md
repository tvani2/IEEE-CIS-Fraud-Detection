# IEEE-CIS-Fraud-Detection
# IEEE-CIS-Fraud-Detection

კონკურსის აღწერა: კონკურსის მიზანია ისეთი მოდელის ტრენინგი, რომელიც მოცემული feature-ების გამოყენებით შეძლებს განსაზღვროს ტრანზაქცია ყალბია თუ არა.

ჩემი მიდგომა: შევისწავლე ორივე ფაილი (identity და transaction) და ეტაპობრივად გავაკეთე მონაცემების cleaning, feature engineering და feature selection. 

რეპოზიტორიის სტრუქტურა: 
model_experiment.ipynb: ფაილი მოიცავს სრულ ანალიტიკურ პროცესს. თითოეული ეტაპი, როგორც ტექნიკური, ისე ლოგიკური თვალსაზრისით სხვადასხვა მოდელისთვის მოცემულია აქ
model_inference.ipynb: აქ ტესტ მონაცემებზე ხდება პროგნოზის აგება შერჩეული საუკეთესო მოდელის გამოყენებით. შედეგად შეიქმნა submissions.csv, რომელიც ავტვირთე Kaggle-ზე. 
README.md: შეიცავს სრულად აღწერილ მიდგომებს, გამოყენებულ მეთოდებსა და ძირითადი ნაბიჯების ახსნას.

Preprocessing: შევამოწმე ორივე ცხრილში NaN მნიშვნელობები. გარკვეული ზღვარი ავიღე, კერძოდ identity-ში 0.9 და transaction-ში 0.6 და დავდროპე სვეტები. შემდეგ გავყავი კატეგორიულ და რიცხვით სვეტებად. დარჩენილი Nan მნიშვნელობები შევავსე mean-ით.  გამოვთვალე woe და iv მნიშვნელობები. threshold-ად ავიღე 3. შემდეგ დავმერჯე ორივე table (ზომა (590540, 277)). გავყავი train და test ნაწილებად. feature selection-თვის გამოვიყენე correlation filter. rfe-იც მინდოდა მარა ძაან დიდხანს მოუნდა და 1.5 საათის მერე გავთიშე. ამ preprocessing-ს ვიყენებდი მოდელების უმრავლესობაზე, მაგრამ შემდეგ გამოვიყენე Undersampling-ც, რათა შეძლებისდაგვარად დამებალანსებინა ცხრილი. მოდელების შესაფასებლად ვიყენებდი recall, precision, f1, roc auc score.

Training: გამოვიყენე რამდენიმე მოდელი:
ჯერ ვცადე Logistic Regression. ბევრი TP მქონდა მაგრამ მაღალი FP მაჩვენებელიც, რაც არ მაწყობდა. Accuracy = 81% მაგრამ რადგან ბევრი 0 გვაქვს isFraud-ში, მთლად სანდო არაა. 
გადავედი Decision Tree-ზე. დავაბალანსე SMOTE-ით, გავტესტე სხვადასხვა სიღრმეზე, min_samples_split : [2, 5, 10]. დიდხანს მოუნდა. Logistic-თან შედარებით გაუმჯობესდა Precision და სხვა მეტრიკებიც, მაგრამ საბოლოოდ კარგი შედეგი მაინც ვერ მივიღე. 
Random Forest-ზე გავტესტე სხვადასხვა model__n_estimators, max_depth, max_features და min_samples_split. მივიღე მაღალი precision მაგრამ დაბალი recall, რადგან max_depth მქონდა ცოტა. ასევე უნდა დამემატებინა class_weight, რათა პრიორიტეტი ჰქონოდა fraud ქეისებს, მაგრამ გატესტვას დიდი დრო უნდოდა და ამ დროს undersampling-ს არ ვიყენებდი. 
Adaboost-მა შედეგი ოდნავ გააუმჯობესა, მაგრამ საერთო ჯამში მაინც ცუდი შედეგი მქონდა. ვფიქრობ preprocessing გავაკეთე ცუდად, იმაზე მეტი სვეტი დავდროპე ვიდრე საჭირო იყო. მაგრამ ზედმეტად დიდი ზომისა და დროის სიმცირის გამო correlation filter, xgboost feature importance-ს გარდა რა გამეკეთებინა ვერ მოვიფიქრე.
რაც შეეხება XGBoost-ს. წესით უკეთესია არადაბალანსებული დატასთვის. თავიდან მარტო კორელაციის ფილტრით ვდროპავდი სვეტებს, მერე გამახსენდა understampling. ბევრი სვეტი დამიდროპა, საბოლოოდ 30-ღა დამრჩა. train-ზე f1 score საშუალოდ 0.65 მქონდა(ვიცი, საშინელებაა)

საბოლოო მოდელის შერჩევის დასაბუთება: თითოეული მოდელისთვის ვეძებდი ოპტიმალურ პარამეტრებს. საბოლოოდ ავირჩიე XGBoost. 
